Build an Artificial Neural Network by implementing the Backpropagation algorithm and test the same using appropriate data sets.
Aim:
 To design and implement an Artificial Neural Network using the backpropagation algorithm and test its performance using the XOR dataset.
Procedure:
•  Initialize the network structure:
•	Input layer: 2 neurons (for XOR inputs)
•	Hidden layer: 2 neurons
•	Output layer: 1 neuron
•  Initialize weights and biases randomly.
•  Feedforward:
•	Compute the output of hidden and output layers using activation functions (e.g., sigmoid).
•  Backpropagation:
•	Compute the error at the output.
•	Calculate gradients.
•	Update weights and biases using gradient descent.
•  Train the network on the XOR dataset for a number of epochs.
•  Test the network with input samples.
Code:
import numpy as np

# Sigmoid activation function and derivative
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_deriv(x):
    return x * (1 - x)

# XOR input and output
X = np.array([[0,0], [0,1], [1,0], [1,1]])  # Inputs
y = np.array([[0], [1], [1], [0]])          # Expected output

# Initialize weights randomly
np.random.seed(1)
weights1 = np.random.rand(2, 2)  # 2 inputs -> 2 hidden
weights2 = np.random.rand(2, 1)  # 2 hidden -> 1 output
bias1 = np.random.rand(1, 2)
bias2 = np.random.rand(1, 1)

# Training loop
for epoch in range(10000):
    # Forward pass
    hidden = sigmoid(np.dot(X, weights1) + bias1)
    output = sigmoid(np.dot(hidden, weights2) + bias2)

    # Backpropagation
    error = y - output
    d_output = error * sigmoid_deriv(output)

    d_hidden = d_output.dot(weights2.T) * sigmoid_deriv(hidden)

    # Update weights and biases
    weights2 += hidden.T.dot(d_output)
    weights1 += X.T.dot(d_hidden)
    bias2 += np.sum(d_output, axis=0, keepdims=True)
    bias1 += np.sum(d_hidden, axis=0, keepdims=True)

# Final output
print("Predicted Output:")
print(np.round(output, 3))

Input:
X = [[0,0], [0,1], [1,0], [1,1]]
y = [[0], [1], [1], [0]]
Output:
Predicted Output:
[[0.01]
 [0.98]
 [0.98]
 [0.02]]

